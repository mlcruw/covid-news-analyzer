
    """
    Test BoW
    """
    train_word_arr = ['the apple was good', 'I flew too close to the sun.']
    train_label = np.random.rand(2)
    data_test = {'X_train': train_word_arr, 'y_train': train_label, 'X_val': train_word_arr, 'y_val': train_label}
    trainer_test = Trainer(data=data_test, models=['gnb', 'svm'], feat='BoW')
    print('Test BoW done')

    """
    Test Word2Vec (gensim)
    """
    sentences = []
    sentences.append(['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']'])
    sentences.append(['Actus', 'Primus', '.'])
    sentences.append(['Fran', '.'])
    train_label = np.random.rand(3)
    data_test = {'X_train': sentences, 'y_train': train_label, 'X_val': sentences, 'y_val': train_label}
    trainer_test = Trainer(data=data_test, models=['gnb', 'svm'], feat='Word2Vec')
    print('Test Word2Vec done')
    
   

   

#   #==============================================================#
#   #1. BoW
#   text = list()
#   for i in range(df.shape[0]):
#     text.append(df.text[i])

#   train_text = text[0: train_num]
#   test_text = text[train_num: train_num + test_num]
#   train_label = [cate_dict[df.category[i]] for i in range(train_num)]
#   test_label = [cate_dict[df.category[i]] for i in range(train_num, train_num + test_num)]

#   data_inp = {'X_train': train_text, 'y_train': train_label, 'X_val': test_text, 'y_val': test_label}

#   trainer = Trainer(data=data_inp, models=cfg.model, feat='BoW')

#   #If continue train from a saved model
#   if cfg.continue_train or cfg.test_only:
#     trainer.load_model(cfg.model[0], 'bow_0')#cfg.load_path)
#   if not(cfg.test_only):
#     trainer.train()
#   metrics = trainer.evaluate()
#   print(metrics)

#   #save model
#   if not(cfg.test_only):
#       trainer.save_model(cfg.model[0], 'bow_1')#cfg.save_path)
#   #==============================================================#
#   #python3 main/train_news.py --dataset news_category_dataset --feat 'BoW' --model linearsvm

#   #python3 main/train_news.py --dataset news_category_dataset --feat 'BoW' --model lr --continue --load_path bow_0 --save_path bow_1


#   #==============================================================#
#   #2. Word2Vec (To-do: train this at a much larger scale Google News?)
#   #Tokenize
#   token = list()
#   for i in range(train_num + test_num):
#     token.append(preprocessor_fn(df.text[i], ['tokenize']))

#   train_token = token[0: train_num]
#   test_token = token[train_num: train_num + test_num]
#   train_label = [cate_dict[df.category[i]] for i in range(train_num)]
#   test_label = [cate_dict[df.category[i]] for i in range(train_num, train_num + test_num)]

#   data_inp = {'X_train': train_token, 'y_train': train_label, 'X_val': test_token, 'y_val': test_label}
#   trainer = Trainer(data=data_inp, models=cfg.model, feat=cfg.feat)

#   #If continue train from a saved model
#   if cfg.continue_train or cfg.test_only:
#       trainer.load_model(cfg.model[0], cfg.load_path)

#   if not(cfg.test_only):
#       trainer.train()
#   metrics = trainer.evaluate()
#   print(metrics)

#   # Save model
#   if not(cfg.test_only):
#     trainer.save_model(cfg.model[0], cfg.save_path)

#   #==============================================================#
#   #python3 main/train_news.py --dataset news_category_dataset --feat 'Word2Vec' --model lr --save_path word2vec_0

#   #python3 main/train_news.py --dataset news_category_dataset --feat 'Word2Vec' --model lr --load_path 'word2vec_0' --test





 num_samples = len(self.data.index)
    num_train_samples = int(train_size * num_samples)
    print('train samples : ', num_train_samples)
 


 # Split data test_ratio is for debugging cuz the whole dataset is too large
  #def split_data(self, test_size):
  #  self.train_data, self.test_data = train_test_split(self.data, test_size=test_size)
    
  # The original one
  def split_data(self, train_split, test_ratio):
    num_samples = len(self.data.index)
    num_train_samples = int(train_split * num_samples)
    num_test_samples = (num_samples - num_train_samples) if test_ratio == 0.0 else int(test_ratio * num_samples)
    print("Spliting the data : %d - %d is train, %d - %d is test" % (0, num_train_samples - 1, num_train_samples, num_train_samples + num_test_samples - 1))
    self.train_data = self.data.iloc[:num_train_samples, :]
    self.test_data = self.data.iloc[num_train_samples: num_train_samples + num_test_samples, :]



# The original enumeration of feature transformations and models in main.py

for model in args.models:
  # TODO: include for feat in args.feats here later

  # Idea is to have a one-to-one mapping between
  # Trainer object and Config object.
  # When saving model in Trainer obj, we could save
  # its corresponding Config object too

  #Note below the usage of [feat] and [model]
  #Added feature selection 
  for feat in args.feats:
      config = Config(dataset=args.dataset,
                  model=model,
                  feats=[feat],
                  save_path=args.save_path,
                  continue_train=args.continue_train,
                  load_path=args.load_path,
                  test=args.test_only)
      # print("Configuration:")
      # print(', '.join("%s: %s" % item for item in vars(config).items()))

      # TODO:
      # - writing everything as pandas dataframe - any downsides?
      # - trainer class
      #   - also create a one-to-one map between Train and Config objects
      # - metrics
      # - save model
      # - modify preprocessor function to use pd.series

      # TODO: passing the config object to trainer?
      # If not passed here, do not comment "import config" in trainer otherwise it does not know the folder path for loading and saving models

      # When calling like this, the mapping from Train and Config is already one-to-one?
      #trainer = Trainer(data=data_inp, models=[model], transforms=[feat], cfg=config)
      trainer = Trainer(dataset=dataset, models=[model], transforms=[feat], cfg=config)
      #1. If continue train from a saved model
      #... example usage of continue_train
      #........python3 main.py --dataset news_cat --models lr --feats bow --split_ratio 0.02 --test_ratio 0.01 --load_path bow_0 --save_path bow_1 -c
      #... example usage of test_only (test PHASE)
      #........python3 main.py --dataset news_cat --models lr --feats bow --split_ratio 0.003 --test_ratio 0.01 --load_path bow_0 -test_only
      if args.continue_train or args.test_only:
         #TO-DO: it can log sth. like "continue training from" or "testing on"
         trainer.load_model(model, args.load_path)
      
      #2. train
      if not(args.test_only):
         trainer.train()

      #3. Metrics evaluation
      metrics = trainer.evaluate()
      print(metrics)

      #4. Update the best acc and config
      if metrics.iloc[0]['precision'] > best_precision:
         best_precision = metrics.iloc[0]['precision']
         best_config = config

      #5. Of course output the evaluation result
      trainer.logger.info('The evaluation result is')
      trainer.logger.info(metrics.to_string())

      #6. save model
      if not(args.test_only):
         trainer.save_model(model, feat, args.save_path)

#Output the best model precision and configuration
trainer.logger.info(['The best model precision is %.2f ' % best_precision])
trainer.logger.info(['The best model configuration is ', ', '.join("%s: %s" % item for item in vars(best_config).items())])

#Sample usage:
#python3 main.py --dataset news_cat --models lr linearsvm --feats bow word2vec  --split_ratio 0.005 --test_ratio 0.01 --save_path best

#python3 main.py --dataset emo_aff --models lr --feats bow ngram tfidf --split_ratio 0.005 --test_ratio 0.2 --save_path best









#data_inp = {'X_train': dataset.train_data['X'], 'y_train': dataset.train_data['y'], 'X_val': dataset.test_data['X'], 'y_val': dataset.test_data['y']}
# The above step takes care of reading the dataset
# and splitting it



# The declaration for the best precision and the best configuration
#best_precision = 0.0
#best_config = Config()




W