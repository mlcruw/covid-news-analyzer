{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/udit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/udit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/udit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from training.argparser import argparser\n",
    "from training.config import Config\n",
    "from training.trainer import Trainer\n",
    "import json\n",
    "# from data.preprocessing import preprocessor_fn\n",
    "\n",
    "from data.stanford_sentiment import StanfordSentimentDataset\n",
    "from data.news_category import NewsCategoryDataset\n",
    "from data.fake_news import FakeNewsDataset\n",
    "from data.emotion_affect import EmotionAffectDataset\n",
    "\n",
    "dataset_map = {\n",
    "  'stan_sent': StanfordSentimentDataset,\n",
    "  'news_cat': NewsCategoryDataset,\n",
    "  'fake_news': FakeNewsDataset,\n",
    "  'emo_aff': EmotionAffectDataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Emotion Affect Dataset\n",
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1207/1207 [00:00<00:00, 4731.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = EmotionAffectDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fake News Dataset\n",
      "\n",
      "Downloading data to data/datasets/fake_news_dataset using the command:\n",
      "   kaggle competitions download -c fake-news\n",
      "Not downloading. Data already downloaded\n",
      "\n",
      "Reading data...\n"
     ]
    }
   ],
   "source": [
    "# dataset = FakeNewsDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Stanford Sentiment Analysis Dataset\n",
      "\n",
      "Downloading data to data/datasets/stanford_sentiment using the command:\n",
      "   kaggle competitions download -c sentiment-analysis-on-movie-reviews\n",
      "Not downloading. Data already downloaded\n",
      "\n",
      "Reading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# dataset = StanfordSentimentDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.train_data['Sentiment'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on News Category Dataset\n",
      "\n",
      "Downloading data to data/datasets/news_category_dataset using the command:\n",
      "   kaggle datasets download rmisra/news-category-dataset\n",
      "Not downloading. Data already downloaded\n",
      "\n",
      "Reading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# dataset = NewsCategoryDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dataset.split_data(dataset_ratio=1.0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 242)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dataset.data), \n",
    "len(dataset.train_data), len(dataset.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for idx in range(dataset.data['X'].values.shape[0]):\n",
    "#     total += len(dataset.data['X'].values[idx])\n",
    "# print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.preprocessing import LemmaTokenizer, StemTokenizer\n",
    "\n",
    "# tokenizer = LemmaTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "# out = tokenizer(' '.join(['styles' for i in range(1000000)]))\n",
    "# print('{:.3f} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(965, 596)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# vect = CountVectorizer(min_df=5, max_features=5000)\n",
    "# X_train = vect.fit_transform(dataset.train_data['X'])\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = PCA(n_components=1000).fit_transform(X_train.todense())\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(dataset=dataset, models=['mnb', 'svm', 'lr', 'ada', 'rf'], transforms=['bow', 'tfidf', 'ngram'])\n",
    "\n",
    "trainer = Trainer(dataset=dataset, models=['mnb', 'lr'], transforms=['bow', 'tfidf'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer2 = Trainer(dataset, models=['lr'], transforms=['bow'])\n",
    "\n",
    "# trainer2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.transformed['bow']['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = trainer.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((965,), (965,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m05-17 04:36:19\u001b[0m Training mnb with bow transformation\n",
      "\u001b[92m05-17 04:36:19\u001b[0m Training mnb with tfidf transformation\n",
      "\u001b[92m05-17 04:36:19\u001b[0m Training lr with bow transformation\n",
      "\u001b[92m05-17 04:36:19\u001b[0m Training lr with tfidf transformation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mnb with bow transformation\n",
      "[Pipeline] .......... (step 1 of 2) Processing tranform, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n",
      "Training mnb with tfidf transformation\n",
      "[Pipeline] .......... (step 1 of 2) Processing tranform, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n",
      "Training lr with bow transformation\n",
      "[Pipeline] .......... (step 1 of 2) Processing tranform, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n",
      "Training lr with tfidf transformation\n",
      "[Pipeline] .......... (step 1 of 2) Processing tranform, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>transform</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mnb</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.812435</td>\n",
       "      <td>0.812435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.729534</td>\n",
       "      <td>0.729534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>0.906736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.812435</td>\n",
       "      <td>0.812435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model transform  precision  accuracy\n",
       "0   mnb       bow   0.812435  0.812435\n",
       "1   mnb     tfidf   0.729534  0.729534\n",
       "2    lr       bow   0.906736  0.906736\n",
       "3    lr     tfidf   0.812435  0.812435"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.gridsearch['svm']['bow'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m05-17 04:36:22\u001b[0m ['The best model precision is 0.91 ']\n",
      "\u001b[92m05-17 04:36:22\u001b[0m ['The best model is lr ']\n",
      "\u001b[92m05-17 04:36:22\u001b[0m ['The best feature transformation is bow ']\n",
      "\u001b[92m05-17 04:36:22\u001b[0m ['The best model configuration is ', 'dataset: news_cat, model: lr, feats: bow, save_path: bow_0, continue_train: False, load_path: None, test: None, params: None']\n",
      "\u001b[92m05-17 04:36:22\u001b[0m   model transform  precision  accuracy\n",
      "0   mnb       bow   0.812435  0.812435\n",
      "1   mnb     tfidf   0.729534  0.729534\n",
      "2    lr       bow   0.906736  0.906736\n",
      "3    lr     tfidf   0.812435  0.812435\n",
      "\u001b[92m05-17 04:36:22\u001b[0m Saving configuration:\n",
      "\u001b[92m05-17 04:36:22\u001b[0m dataset: news_cat, model: lr, feats: bow, save_path: bow_0, continue_train: False, load_path: None, test: None, params: None\n",
      "\u001b[92m05-17 04:36:22\u001b[0m Saving done\n"
     ]
    }
   ],
   "source": [
    "trainer.save_best(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | model   | transform   |   precision |   accuracy |\n",
      "|---:|:--------|:------------|------------:|-----------:|\n",
      "|  0 | mnb     | bow         |    0.801036 |   0.801036 |\n",
      "|  1 | mnb     | tfidf       |    0.731606 |   0.731606 |\n",
      "|  2 | mnb     | ngram       |    0.801036 |   0.801036 |\n",
      "|  3 | svm     | bow         |    0.982383 |   0.982383 |\n",
      "|  4 | svm     | tfidf       |    0.941969 |   0.941969 |\n",
      "|  5 | svm     | ngram       |    0.864249 |   0.864249 |\n",
      "|  6 | lr      | bow         |    0.906736 |   0.906736 |\n",
      "|  7 | lr      | tfidf       |    0.801036 |   0.801036 |\n",
      "|  8 | lr      | ngram       |    0.905699 |   0.905699 |\n",
      "|  9 | xgb     | bow         |    0.772021 |   0.772021 |\n",
      "| 10 | xgb     | tfidf       |    0.846632 |   0.846632 |\n",
      "| 11 | xgb     | ngram       |    0.770984 |   0.770984 |\n",
      "| 12 | ada     | bow         |    0.541969 |   0.541969 |\n",
      "| 13 | ada     | tfidf       |    0.60829  |   0.60829  |\n",
      "| 14 | ada     | ngram       |    0.541969 |   0.541969 |\n",
      "| 15 | rf      | bow         |    0.832124 |   0.832124 |\n",
      "| 16 | rf      | tfidf       |    0.969948 |   0.969948 |\n",
      "| 17 | rf      | ngram       |    0.823834 |   0.823834 |\n"
     ]
    }
   ],
   "source": [
    "print(df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "{} & model & transform &  precision &    recall &  f1-score \\\\\n",
      "\\midrule\n",
      "0 &   mnb &       bow &   0.804145 &  0.804145 &  0.804145 \\\\\n",
      "1 &   svm &       bow &   0.872539 &  0.872539 &  0.872539 \\\\\n",
      "2 &    lr &       bow &   0.912953 &  0.912953 &  0.912953 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trainer.gridsearch['lr']['bow'].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 2, 2, 2, 1, 1, 1, 5, 2, 2, 2, 2, 2, 1, 1, 1, 4,\n",
       "       0, 5, 0, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 5, 0, 4, 5, 5, 0,\n",
       "       0, 5, 0, 5, 4, 4, 2, 4, 0, 1, 2, 1, 1, 0, 5, 0, 2, 2, 0, 5, 0, 5,\n",
       "       1, 2, 4, 1, 1, 5, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       2, 2, 0, 1, 1, 1, 1, 1, 5, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 5,\n",
       "       2, 0, 1, 1, 1, 1, 0, 0, 2, 0, 1, 4, 1, 0, 2, 1, 4, 4, 4, 2, 0, 2,\n",
       "       2, 1, 1, 4, 0, 1, 2, 2, 5, 0, 1, 2, 5, 1, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 2, 2, 2, 4, 2, 2, 2, 4, 2,\n",
       "       4, 4, 1, 1, 1, 2, 0, 1, 2, 5, 2, 0, 0, 1, 0, 1, 2, 2, 5, 5, 2, 2,\n",
       "       0, 0, 0, 0, 0, 4, 4, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 1,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 4, 2, 2, 5, 0, 2, 0, 0, 4,\n",
       "       4, 4, 0, 4, 4, 4, 4, 4, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 2, 4, 5, 2, 2, 2, 2, 4, 4, 0, 5, 0, 2, 2, 2, 1, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 2, 4, 4, 0, 0, 0, 0, 2, 2, 2, 4, 4, 4, 4, 4, 5,\n",
       "       2, 5, 4, 4, 1, 2, 5, 2, 2, 2, 4, 2, 2, 2, 5, 2, 2, 0, 2, 2, 0, 5,\n",
       "       2, 2, 2, 2, 0, 4, 4, 0, 2, 4, 2, 5, 4, 4, 2, 5, 5, 0, 0, 2, 2, 5,\n",
       "       4, 0, 1, 5, 5, 2, 2, 1, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 0, 4, 4, 2,\n",
       "       2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 4, 0, 2, 4, 4, 1, 1, 4, 5, 2, 2, 2,\n",
       "       4, 2, 4, 4, 4, 0, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4,\n",
       "       4, 2, 2, 4, 1, 2, 2, 1, 0, 4, 0, 1, 4, 2, 2, 2, 2, 2, 2, 2, 2, 5,\n",
       "       0, 0, 2, 0, 2, 5, 2, 0, 4, 2, 2, 4, 4, 4, 4, 2, 1, 4, 4, 2, 4, 4,\n",
       "       5, 1, 2, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 0, 2,\n",
       "       2, 2, 1, 4, 4, 2, 4, 2, 2, 1, 4, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2,\n",
       "       0, 1, 5, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 5, 2, 0, 0,\n",
       "       0, 2, 4, 4, 2, 4, 2, 0, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 2, 2,\n",
       "       2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 0, 0, 0, 0, 0, 0, 4, 0, 0,\n",
       "       0, 1, 1, 1, 4, 1, 4, 4, 0, 2, 2, 1, 5, 0, 2, 4, 2, 2, 2, 0, 0, 1,\n",
       "       0, 2, 2, 4, 4, 4, 2, 2, 5, 2, 2, 4, 0, 4, 5, 5, 4, 4, 1, 2, 4, 4,\n",
       "       5, 2, 1, 1, 4, 2, 2, 2, 0, 0, 0, 5, 4, 4, 2, 2, 0, 0, 2, 5, 2, 0,\n",
       "       2, 0, 0, 1, 2, 4, 4, 4, 1, 1, 2, 5, 5, 2, 0, 0, 0, 0, 2, 2, 4, 1,\n",
       "       0, 0, 5, 2, 2, 5, 0, 4, 0, 2, 2, 4, 5, 2, 5, 2, 0, 5, 0, 0, 5, 0,\n",
       "       4, 2, 1, 1, 4, 4, 2, 4, 2, 2, 4, 0, 2, 1, 4, 4, 2, 2, 2, 5, 0, 0,\n",
       "       0, 2, 0, 2, 1, 2, 4, 0, 0, 0, 2, 2, 5, 0, 1, 0, 4, 4, 2, 2, 1, 4,\n",
       "       4, 4, 2, 0, 2, 0, 4, 2, 5, 0, 2, 4, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0,\n",
       "       5, 0, 2, 0, 0, 2, 5, 2, 0, 5, 5, 0, 4, 4, 4, 5, 5, 1, 5, 5, 1, 4,\n",
       "       2, 2, 1, 2, 2, 2, 0, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2,\n",
       "       2, 1, 0, 0, 0, 4, 4, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 4, 2, 1, 2,\n",
       "       4, 4, 4, 4, 4, 4, 2, 2, 5, 1, 2, 4, 4, 4, 5, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2,\n",
       "       1, 1, 1, 4, 1, 1, 1, 2, 2, 2, 1, 1, 4, 4, 2, 0, 0, 0, 0, 0, 2, 4,\n",
       "       4, 1, 2, 2, 4, 2, 1, 2, 2, 2, 2, 1, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 1, 1, 4, 4, 4, 2, 2, 2, 1, 2, 4, 0, 2, 2, 2, 2, 4, 4, 4,\n",
       "       2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 4,\n",
       "       4, 2, 0, 0, 4, 5, 4, 5, 2, 2, 5, 0, 0, 0, 1, 4, 4, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "with open('test.pkl', 'wb') as fw:\n",
    "    pickle.dump(best_pipeline, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=20, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='elasticnet', power_t=0.5,\n",
       "                               random_state=None, shuffle=True, tol=0.001,\n",
       "                               validation_fraction=0.1, verbose=0,\n",
       "                               warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "params = {'stop_words':'english', 'min_df':5}\n",
    "\n",
    "vect = CountVectorizer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('covid19_articles/covid_19_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 SGDClassifier(alpha=1e-06, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=20, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='elasticnet', power_t=0.5,\n",
       "                               random_state=None, shuffle=True, tol=0.001,\n",
       "                               validation_fraction=0.1, verbose=0,\n",
       "                               warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline.predict(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Angry-Disgusted\n",
       "1     Angry-Disgusted\n",
       "2               HAPPY\n",
       "3               HAPPY\n",
       "4               HAPPY\n",
       "5           Surprised\n",
       "6           Surprised\n",
       "7             Fearful\n",
       "8                 Sad\n",
       "9             Fearful\n",
       "10    Angry-Disgusted\n",
       "11          Surprised\n",
       "12          Surprised\n",
       "13                Sad\n",
       "14            Fearful\n",
       "15          Surprised\n",
       "16            Fearful\n",
       "17          Surprised\n",
       "18          Surprised\n",
       "19            Fearful\n",
       "Name: Emotion 1-7, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion 1-7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "article0 = data['text'][0]\n",
    "\n",
    "def eval_emotion(article_text):\n",
    "    sentences = sent_tokenize(article_text)\n",
    "    pred_emotions = loaded_pipeline.predict(sentences)\n",
    "    final_emotion = stats.mode(pred_emotions).mode[0]\n",
    "    return final_emotion\n",
    "\n",
    "print(eval_emotion(article0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(article_text):\n",
    "    # load all 4 models\n",
    "    # run predictions on all 4 models\n",
    "    # return a dict {\"emotion\": pred_emotion, \"category\": pred_category, \"fake\": pred_fake, \"sentiment\": pred_sentiment}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emo.model           emo_aff.csv         emo_aff_clean.csv   emo_aff_results.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/model_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('output/model_dump/emo_aff_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "{} &      model & transform &  precision &  accuracy \\\\\n",
      "\\midrule\n",
      "0 &         lr &       bow &   0.906736 &  0.906736 \\\\\n",
      "1 &         lr &     ngram &   0.912953 &  0.912953 \\\\\n",
      "2 &  linearsvm &       bow &   0.960622 &  0.960622 \\\\\n",
      "3 &  linearsvm &     ngram &   0.962694 &  0.962694 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv('output/model_dump/emo_aff_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it is very unpleasant i am afraid of the polic...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickle nearly had a fit he barked and he barke...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he shut the door in nutkins face</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old mr brown turned up his eye in disgust at t...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and to this day if you meet nutkin up a tree a...</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>ah said the father what fear we have had for you</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>yes father answered he i have travelled all ov...</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>well said they you are come back and we will n...</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>then they hugged and kissed their dear little ...</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>so master thumb stayed at home with his father...</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1207 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X  y  index\n",
       "0     it is very unpleasant i am afraid of the polic...  1     35\n",
       "1     pickle nearly had a fit he barked and he barke...  0     46\n",
       "2                      he shut the door in nutkins face  0     24\n",
       "3     old mr brown turned up his eye in disgust at t...  0     51\n",
       "4     and to this day if you meet nutkin up a tree a...  0     77\n",
       "...                                                 ... ..    ...\n",
       "1202   ah said the father what fear we have had for you  2     98\n",
       "1203  yes father answered he i have travelled all ov...  2     99\n",
       "1204  well said they you are come back and we will n...  2    102\n",
       "1205  then they hugged and kissed their dear little ...  2    103\n",
       "1206  so master thumb stayed at home with his father...  2    104\n",
       "\n",
       "[1207 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Stanford Sentiment Analysis Dataset\n",
      "\n",
      "Downloading data to data/datasets/stanford_sentiment using the command:\n",
      "   kaggle competitions download -c sentiment-analysis-on-movie-reviews\n",
      "Not downloading. Data already downloaded\n",
      "\n",
      "Reading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dataset = StanfordSentimentDataset(do_clean=False)\n",
    "data_path = 'output/model_dump/stan_sent_clean.csv'\n",
    "if os.path.exists(data_path):\n",
    "    clean_data = pd.read_csv(data_path)\n",
    "    dataset.data = clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a series of escapade demonstrating the adage t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a series of escapade demonstrating the adage t...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a series</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>hearst s</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>forced avuncular chortle</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>avuncular chortle</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>avuncular</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>chortle</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        X    y\n",
       "0       a series of escapade demonstrating the adage t...  1.0\n",
       "1       a series of escapade demonstrating the adage t...  2.0\n",
       "2                                                a series  2.0\n",
       "3                                                       a  2.0\n",
       "4                                                  series  2.0\n",
       "...                                                   ...  ...\n",
       "156055                                           hearst s  2.0\n",
       "156056                           forced avuncular chortle  1.0\n",
       "156057                                  avuncular chortle  3.0\n",
       "156058                                          avuncular  2.0\n",
       "156059                                            chortle  2.0\n",
       "\n",
       "[156060 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    159\n",
       "y      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fake News Dataset\n",
      "\n",
      "Downloading data to data/datasets/fake_news_dataset using the command:\n",
      "   kaggle competitions download -c fake-news\n",
      "Not downloading. Data already downloaded\n",
      "\n",
      "Reading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dataset = FakeNewsDataset(do_clean=False)\n",
    "data_path = 'output/model_dump/fake_news_clean.csv'\n",
    "if os.path.exists(data_path):\n",
    "    clean_data = pd.read_csv(data_path)\n",
    "    dataset.data = clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide we didnt even see comeys letter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillary clinton big woman on campus brei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the truth might get you fired why the trut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>civilian killed in single u airstrike have bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>rapper ti trump a poster child for white supre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20199</th>\n",
       "      <td>nfl playoff schedule matchup and odds the new ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200</th>\n",
       "      <td>macys is said to receive takeover approach by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201</th>\n",
       "      <td>nato russia to hold parallel exercise in balka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20202</th>\n",
       "      <td>what keep the f alive david swanson is an auth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       X  y\n",
       "0      house dem aide we didnt even see comeys letter...  1\n",
       "1      flynn hillary clinton big woman on campus brei...  0\n",
       "2      why the truth might get you fired why the trut...  1\n",
       "3      civilian killed in single u airstrike have bee...  1\n",
       "4      iranian woman jailed for fictional unpublished...  1\n",
       "...                                                  ... ..\n",
       "20198  rapper ti trump a poster child for white supre...  0\n",
       "20199  nfl playoff schedule matchup and odds the new ...  0\n",
       "20200  macys is said to receive takeover approach by ...  0\n",
       "20201  nato russia to hold parallel exercise in balka...  1\n",
       "20202  what keep the f alive david swanson is an auth...  1\n",
       "\n",
       "[20161 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dataset.split_data(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16162</th>\n",
       "      <td>clinton id add michelle obama to my cabinet ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16163</th>\n",
       "      <td>johnny nicholson whose midtown cafe drew the n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16164</th>\n",
       "      <td>reichsbrger schlagen zu sind beamte fr reichsi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16165</th>\n",
       "      <td>an open letter to black south african police o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16166</th>\n",
       "      <td>u investigating mosul strike said to have kill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20198</th>\n",
       "      <td>rapper ti trump a poster child for white supre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20199</th>\n",
       "      <td>nfl playoff schedule matchup and odds the new ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200</th>\n",
       "      <td>macys is said to receive takeover approach by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201</th>\n",
       "      <td>nato russia to hold parallel exercise in balka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20202</th>\n",
       "      <td>what keep the f alive david swanson is an auth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       X  y\n",
       "16162  clinton id add michelle obama to my cabinet ho...  1\n",
       "16163  johnny nicholson whose midtown cafe drew the n...  0\n",
       "16164  reichsbrger schlagen zu sind beamte fr reichsi...  1\n",
       "16165  an open letter to black south african police o...  1\n",
       "16166  u investigating mosul strike said to have kill...  0\n",
       "...                                                  ... ..\n",
       "20198  rapper ti trump a poster child for white supre...  0\n",
       "20199  nfl playoff schedule matchup and odds the new ...  0\n",
       "20200  macys is said to receive takeover approach by ...  0\n",
       "20201  nato russia to hold parallel exercise in balka...  1\n",
       "20202  what keep the f alive david swanson is an auth...  1\n",
       "\n",
       "[4041 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide we didnt even see comeys letter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillary clinton big woman on campus brei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the truth might get you fired why the trut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>civilian killed in single u airstrike have bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16157</th>\n",
       "      <td>suicide bomb attack target baghdad market afp ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16158</th>\n",
       "      <td>watch mandy moore is shark bait in meter down ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16159</th>\n",
       "      <td>re wannnh the left melt down after fbi reopens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16160</th>\n",
       "      <td>donald trump call a black supporter a paid thu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>report huma abedin finally file for divorce fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16162 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       X  y\n",
       "0      house dem aide we didnt even see comeys letter...  1\n",
       "1      flynn hillary clinton big woman on campus brei...  0\n",
       "2      why the truth might get you fired why the trut...  1\n",
       "3      civilian killed in single u airstrike have bee...  1\n",
       "4      iranian woman jailed for fictional unpublished...  1\n",
       "...                                                  ... ..\n",
       "16157  suicide bomb attack target baghdad market afp ...  0\n",
       "16158  watch mandy moore is shark bait in meter down ...  0\n",
       "16159  re wannnh the left melt down after fbi reopens...  1\n",
       "16160  donald trump call a black supporter a paid thu...  1\n",
       "16161  report huma abedin finally file for divorce fr...  0\n",
       "\n",
       "[16162 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37464bitmlcondaa8f3f69cf251458aa86fbbc582b758f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
